export async function checkWithLLM(text: string) {
  try {
    const resp = await fetch("http://localhost:11434/api/generate", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: "mistral", // tambi√©n puedes usar llama3, gemma, etc.
        prompt: `
Detecta groser√≠as en este texto y responde SOLO en JSON v√°lido:
{"hits":[{"term":"...","start":0,"end":4,"severity":2}]}

Texto:
${text}
        `,
      }),
    });

    const data = await resp.text();

    // üõ†Ô∏è Ollama responde en streaming, por eso a veces llega texto extra.
    // Aqu√≠ buscamos el √∫ltimo JSON en la respuesta.
    const jsonStart = data.lastIndexOf("{");
    if (jsonStart === -1) return [];

    const parsed = JSON.parse(data.slice(jsonStart));
    return parsed.hits ?? [];
  } catch (err) {
    console.error("Error llamando a Ollama:", err);
    return [];
  }
}
